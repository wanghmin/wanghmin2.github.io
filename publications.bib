@inproceedings{dai-2024-hqs,
author = {Dai, Pinxuan and Xu, Jiamin and Xie, Wenxiang and Liu, Xinguo and Wang, Huamin and Xu, Weiwei},
title = {High-quality Surface Reconstruction using Gaussian Surfels},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657441},
doi = {10.1145/3641519.3657441},
abstract = {We propose a novel point-based representation, Gaussian surfels, to combine the advantages of the flexible optimization procedure in 3D Gaussian points and the surface alignment property of surfels. This is achieved by directly setting the z-scale of 3D Gaussian points to 0, effectively flattening the original 3D ellipsoid into a 2D ellipse. Such a design provides clear guidance to the optimizer. By treating the local z-axis as the normal direction, it greatly improves optimization stability and surface alignment. While the derivatives to the local z-axis computed from the covariance matrix are zero in this setting, we design a self-supervised normal-depth consistency loss to remedy this issue. Monocular normal priors and foreground masks are incorporated to enhance the quality of the reconstruction, mitigating issues related to highlights and background. We propose a volumetric cutting method to aggregate the information of Gaussian surfels so as to remove erroneous points in depth maps generated by alpha blending. Finally, we apply screened Poisson reconstruction method to the fused depth maps to extract the surface mesh. Experimental results show that our method demonstrates superior performance in surface reconstruction compared to state-of-the-art neural volume rendering and point-based rendering methods.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {22},
numpages = {11},
keywords = {3D Surface Reconstruction, Depth-normal Consistency, Gaussian Surfels},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{feng-2024-nah,
author = {Feng, Xudong and Wang, Huamin and Yang, Yin and Xu, Weiwei},
title = {Neural-Assisted Homogenization of Yarn-Level Cloth},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657411},
doi = {10.1145/3641519.3657411},
abstract = {Real-world fabrics, composed of threads and yarns, often display complex stress-strain relationships, making their homogenization a challenging task for fast simulation by continuum-based models. Consequently, existing homogenized yarn-level models frequently struggle with numerical stability without line search at large time steps, forcing a trade-off between model accuracy and stability. In this paper, we propose a neural-assisted homogenized constitutive model for simulating yarn-level cloth. Unlike analytic models, a neural model is advantageous in adapting to complex dynamic behaviors, and its inherent smoothness naturally mitigates stability issues. We also introduce a sector-based warm-start strategy to accelerate the data collection process in homogenization. This model is trained using collected strain energy datasets and its accuracy is validated through both qualitative and quantitative experiments. Thanks to our model’s stability, our simulator can now achieve two-orders-of-magnitude speedups with large time steps compared to previous models.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {80},
numpages = {10},
keywords = {Constitutive Model, Homogenization, Neural Networks, Yarn-level Cloth Simulation},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{jiang-2024-vrgs,
author = {Jiang, Ying and Yu, Chang and Xie, Tianyi and Li, Xuan and Feng, Yutao and Wang, Huamin and Li, Minchen and Lau, Henry and Gao, Feng and Yang, Yin and Jiang, Chenfanfu},
title = {VR-GS: A Physical Dynamics-Aware Interactive Gaussian Splatting System in Virtual Reality},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657448},
doi = {10.1145/3641519.3657448},
abstract = {As 3D content becomes increasingly prevalent, there’s a growing focus on the development of engagements with 3D virtual content. Unfortunately, traditional techniques for creating, editing, and interacting with this content are fraught with difficulties. They tend to be not only engineering-intensive but also require extensive expertise, which adds to the frustration and inefficiency in virtual object manipulation. Our proposed VR-GS system represents a leap forward in human-centered 3D content interaction, offering a seamless and intuitive user experience. By developing a physical dynamics-aware interactive Gaussian Splatting (GS) in a Virtual Reality (VR) setting, and constructing a highly efficient two-level embedding strategy alongside deformable body simulations, VR-GS ensures real-time execution with highly realistic dynamic responses. The components of our system are designed for high efficiency and effectiveness, starting from detailed scene reconstruction and object segmentation, advancing through multi-view image in-painting, and extending to interactive physics-based editing. The system also incorporates real-time deformation embedding and dynamic shadow casting, ensuring a comprehensive and engaging virtual experience.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {78},
numpages = {1},
keywords = {Gaussian Splatting, Neural Radiance Fields, Real-Time Interactions},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{li-2024-add,
author = {Li, Xuan and Li, Minchen and Han, Xuchen and Wang, Huamin and Yang, Yin and Jiang, Chenfanfu},
title = {A Dynamic Duo of Finite Elements and Material Points},
year = {2024},
isbn = {9798400705250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641519.3657449},
doi = {10.1145/3641519.3657449},
abstract = {This paper presents a novel method to couple Finite Element Methods (FEM), typically employed for modeling Lagrangian solids such as flesh, cloth, hair, and rigid bodies, with Material Point Methods (MPM), which are well-suited for simulating materials undergoing substantial deformation and topology change, including Newtonian/non-Newtonian fluid, granular materials, and fracturing materials. The challenge of coupling these diverse methods arises from their contrasting computational needs: implicit FEM integration is often favored to enjoy stability and large timesteps, while explicit MPM integration benefits from its allowance for efficient GPU optimization and flexibility of applying different plasticity models, which only allows for moderate timesteps. To bridge this gap, a mixed implicit-explicit time integration (IMEX) approach is proposed, utilizing principles from time splitting for partial differential equations and optimization-based time integrators. This method adopts incremental potential contact (IPC) to define a variational frictional contact model between the two materials, serving as the primary coupling mechanism. Our method enables implicit FEM and explicit MPM to coexist with significantly different timestep sizes while preserving two-way coupling. Experimental results demonstrate the potential of our method as a strong foundation for future exploration and enhancement in the field of multi-material simulation.},
booktitle = {ACM SIGGRAPH 2024 Conference Papers},
articleno = {97},
numpages = {11},
keywords = {asynchronous time integration, finite element method, frictional contact, material point method, optimization time integration, time splitting},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@article{liu-2024-adg,
author = {Liu, Chen and Xu, Weiwei and Yang, Yin and Wang, Huamin},
title = {Automatic Digital Garment Initialization from Sewing Patterns},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3658128},
doi = {10.1145/3658128},
abstract = {The rapid advancement of digital fashion and generative AI technology calls for an automated approach to transform digital sewing patterns into well-fitted garments on human avatars. When given a sewing pattern with its associated sewing relationships, the primary challenge is to establish an initial arrangement of sewing pieces that is free from folding and intersections. This setup enables a physics-based simulator to seamlessly stitch them into a digital garment, avoiding undesirable local minima. To achieve this, we harness AI classification, heuristics, and numerical optimization. This has led to the development of an innovative hybrid system that minimizes the need for user intervention in the initialization of garment pieces. The seeding process of our system involves the training of a classification network for selecting seed pieces, followed by solving an optimization problem to determine their positions and shapes. Subsequently, an iterative selection-arrangement procedure automates the selection of pattern pieces and employs a phased initialization approach to mitigate local minima associated with numerical optimization. Our experiments confirm the reliability, efficiency, and scalability of our system when handling intricate garments with multiple layers and numerous pieces. According to our findings, 68 percent of garments can be initialized with zero user intervention, while the remaining garments can be easily corrected through user operations.},
journal = {ACM Trans. Graph. (SIGGRAPH)},
month = jul,
articleno = {74},
numpages = {12},
keywords = {physics-based cloth simulation, numerical optimization, digital fashion, local minima, sewing pattern}
}

@article{lan-2024-egc,
author = {Lan, Lei and Lu, Zixuan and Long, Jingyi and Yuan, Chun and Li, Xuan and He, Xiaowei and Wang, Huamin and Jiang, Chenfanfu and Yang, Yin},
title = {Efficient GPU Cloth Simulation with Non-distance Barriers and Subspace Reuse},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687760},
doi = {10.1145/3687760},
abstract = {This paper pushes the performance of cloth simulation, making the simulation interactive even for high-resolution garment models while keeping every triangle untangled. The penetration-free guarantee is inspired by the nterior point method, which converts the inequality constraints to barrier potentials. We propose a major overhaul of this modality within the projective dynamics framework by leveraging an adaptive weighting mechanism inspired by barrier formulation. This approach does not depend on the distance between mesh primitives, but on the virtual life span of a collision event and thus keeps all the vertices within feasible region. Such a nondistance barrier model allows a new way to integrate collision resolution into the simulation pipeline. Another contributor to the performance boost comes from the subspace reuse strategy. This is based on the observation that low-frequency strain propagation is near orthogonal to the deformation induced by collisions or self-collisions, often of high frequency. Subspace reuse then takes care of low-frequency residuals, while high-frequency residuals can also be effectively smoothed by GPU-based iterative solvers. We show that our method outperforms existing fast cloth simulators by at least one order while producing high-quality animations of high-resolution models.},
journal = {ACM Trans. Graph. (SIGGRAPH Asia)},
month = dec,
articleno = {226},
numpages = {16},
keywords = {GPU simulation, cloth animation, collision detection, parallel computation}
}

@article{yuan-2024-vhk,
author = {Yuan, Chun and Shi, Haoyang and Lan, Lei and Qiu, Yuxing and Yuksel, Cem and Wang, Huamin and Jiang, Chenfanfu and Wu, Kui and Yang, Yin},
title = {Efficient GPU Cloth Simulation with Non-distance Barriers and Subspace Reuse},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687911},
doi = {10.1145/3687911},
abstract = {This paper presents volumetric homogenization, a spatially varying homogenization scheme for knitwear simulation. We are motivated by the observation that macro-scale fabric dynamics is strongly correlated with its underlying knitting patterns. Therefore, homogenization towards a single material is less effective when the knitting is complex and non-repetitive. Our method tackles this challenge by homogenizing the yarn-level material locally at volumetric elements. Assigning a virtual volume of a knitting structure enables us to model bending and twisting effects via a simple volumepreserving penalty and thus effectively alleviates the material nonlinearity. We employ an adjoint Gauss-Newton formulation[Zehnder et al. 2021] to battle the dimensionality challenge of such per-element material optimization. This intuitive material model makes the forward simulation GPU-friendly. To this end, our pipeline also equips a novel domain-decomposed subspace solver crafted for GPU projective dynamics, which makes our simulator hundreds of times faster than the yarn-level simulator. Experiments validate the capability and effectiveness of volumetric homogenization. Our method produces realistic animations of knitwear matching the quality of full-scale yarn-level simulations. It is also orders of magnitude faster than existing homogenization techniques in both the training and simulation stages.},
journal = {ACM Trans. Graph. (SIGGRAPH Asia)},
month = dec,
articleno = {207},
numpages = {19},
keywords = {yarn-level simulation, homogenization, physics-based simulation, domain decomposition}
}

@inproceedings{hu-2024-mfr,
  author       = {Hu, Rui and He, Qian and Zhuang, Jiedong and Chen, Huang and Liu, Huafeng and Wang, Huamin},
  title        = {Make Fashion Real: Texture-preserving Rendered-to-Real Translation with Diffusion Models},
  booktitle    = {Advances in Neural Information Processing Systems 38: Annual Conference
                  on Neural Information Processing Systems 2024, NeurIPS 2024, Vancouver, Canada, December 10 - 15, 2024},
  year         = {2024},
}
